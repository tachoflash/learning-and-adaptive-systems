# -*- coding: utf-8 -*-
"""MNIST_Handwritten_Digits_STARTER.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MpYVIAMvz8jMQ_hct7YVaXIQ5Z_Edbci

# CIT-223-022/2021
# EDWIN KIPNGETICH

# Introduction

In this task, I am coming up with a neural model to evaluate the MNIST dataset.

Some of the benchmark results on MNIST include can be found [on Yann LeCun's page](https://webcache.googleusercontent.com/search?q=cache:stAVPik6onEJ:yann.lecun.com/exdb/mnist) and include:


95.3% [Lecun et al., 1998](https://hal.science/hal-03926082v1/document)

99.65% [Ciresan et al., 2011](http://people.idsia.ch/~juergen/ijcai2011.pdf)


MNIST is a great dataset bacause it's simple and  the accuracy levels achieved by large convolutional neural networks and small linear models are both quite high. It is perfect for image classification models.
## Installation process
"""

# prompt: change this such that I can read requirements.txt from google drive

from google.colab import drive
drive.mount('/content/drive')

import os
os.listdir('/content/drive/MyDrive/')

!pip install -r /content/drive/MyDrive/requirements.txt

"""## Imports"""

## This cell contains the essential imports you will need – DO NOT CHANGE THE CONTENTS! ##
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import os

from torchvision import datasets
from torch.utils.data import DataLoader

"""## Load the Dataset

Specify your transforms as a list if you intend to .
The transforms module is already loaded as `transforms`.

MNIST is fortunately included in the torchvision module.
Then, you can create your dataset using the `MNIST` object from `torchvision.datasets` ([the documentation is available here](https://pytorch.org/vision/stable/datasets.html#mnist)).
Make sure to specify `download=True`!

Once your dataset is created, you'll also need to define a `DataLoader` from the `torch.utils.data` module for both the train and the test set.
"""

DATA_PATH = os.getcwd()
if "Data" not in os.listdir():
    os.makedirs('Data')
DATA_PATH = os.path.join(os.getcwd(), "Data")
print(DATA_PATH)

# Define transforms
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, ), (0.5, )),
                               transforms.RandomRotation((5, 355)),
#                                 transforms.GaussianBlur(kernel_size = (5, 5))
                               ])

# Create training set and define training dataloader
dataset = datasets.MNIST(root = DATA_PATH, train = True, transform = transform, download = True)
train_data, val_data = torch.utils.data.random_split(dataset, [50000, 10000], torch.Generator().manual_seed(42))
test_data = datasets.MNIST(root = DATA_PATH, train = False, transform = transform, download = True)

# Create test set and define test dataloader
train_loader = DataLoader(train_data, batch_size = 32, shuffle = True)
val_loader = DataLoader(val_data, batch_size = 32, shuffle = True)
test_loader = DataLoader(test_data, batch_size = 32)

"""## Justify your preprocessing

In your own words, why did you choose the transforms you chose? If you didn't use any preprocessing steps, why not?

### transforms.ToTensor():

Deep learning models typically require input data in the form of tensors. This transformation scales the pixel values of the image from the range [0, 255] to the range [0, 1] by dividing by 255.0.

### transforms.Normalize((0.5, ), (0.5, )):

Normalization helps in speeding up the training process and achieving better convergence. It helps to standardize the inputs, making the model training more stable and efficient.

### transforms.RandomRotation((5, 355)):

Data augmentation technique used to increase the diversity of the training dataset and improve the robustness of the model.

## Explore the Dataset
Using matplotlib, numpy, and torch, explore the dimensions of your data.

You can view images using the `show5` function defined below – it takes a data loader as an argument.
Remember that normalized images will look really weird to you! You may want to try changing your transforms to view images.
Typically using no transforms other than `toTensor()` works well for viewing – but not as well for training your network.
If `show5` doesn't work, go back and check your code for creating your data loaders and your training/test sets.
"""

## This cell contains a function for showing 5 images from a dataloader – DO NOT CHANGE THE CONTENTS! ##
def show5(img_loader):
    dataiter = iter(img_loader)

    batch = next(dataiter)
    labels = batch[1][0:5]
    images = batch[0][0:5]
    for i in range(5):
        print(int(labels[i].detach()))

        image = images[i].numpy()
        plt.imshow(image.T.squeeze().T)
        plt.show()
show5(train_loader)

# Explore data
print(f"Total number of train images: {len(train_data)}")
print(f"Total number of validation images: {len(val_data)}")
print(f"Total number of test images: {len(test_data)}")

print(f"Train classes: {test_data.classes}")

print(f"Image shape: {train_data[5][0].shape}")
print("Image 5 label: {}".format(train_data[5][1]))

"""## Build your Neural Network
Using the layers in `torch.nn` (which has been imported as `nn`) and the `torch.nn.functional` module (imported as `F`), construct a neural network based on the parameters of the dataset.
Use any architecture you like.

*Note*: If you did not flatten your tensors in your transforms or as part of your preprocessing and you are using only `Linear` layers, make sure to use the `Flatten` layer in your network!
"""

28*28

class model(nn.Module):
    def __init__(self):
        super().__init__()
        self.activation = F.relu
        self.layer1 = nn.Linear(784, 512)
        self.layer2 = nn.Linear(512, 256)
        self.layer3 = nn.Linear(256, 128)
        self.layer4 = nn.Linear(128, 10)

    def forward(self, x):
        x =  torch.flatten(x, 1)
        x = self.activation(self.layer1(x))
        x = self.activation(self.layer2(x))
        x = self.activation(self.layer3(x))
        x = self.layer4(x)
        return x

model = model()

"""Specify a loss function and an optimizer, and instantiate the model.

If you use a less common loss function, please note why you chose that loss function in a comment.
"""

optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)

criterion = nn.CrossEntropyLoss()

"""## Running your Neural Network
Use whatever method you like to train your neural network, and ensure you record the average loss at each epoch.
Don't forget to use `torch.device()` and the `.to()` method for both your model and your data if you are using GPU!

If you want to print your loss **during** each epoch, you can use the `enumerate` function and print the loss after a set number of batches. 250 batches works well for most people!
"""

def train_model(model, train_loader, val_loader, optimizer, criterion, EPOCHS = 10):
    if torch.cuda.is_available():
        model = model.cuda()

    train_losses = list()
    train_accuracy = list()

    val_losses = list()
    val_accuracy = list()

    for epoch in range(EPOCHS):
        model.train()

        train_loss = 0
        train_correct = 0

        val_loss = 0
        val_correct = 0

        for data in train_loader:
            images, labels = data

            if torch.cuda.is_available():
                images, labels = images.cuda(), labels.cuda()

            optimizer.zero_grad()

            outputs = model(images)
            loss = criterion(outputs, labels)

            loss.backward()
            optimizer.step()

            _, predictions = torch.max(outputs.data, 1)
            train_correct += sum(predictions == labels)/len(predictions == labels)
            train_loss += loss.item()

        train_losses.append(train_loss/len(train_loader))
        train_accuracy.append(train_correct/len(train_loader))
        print(f"Epoch: {epoch+1} Train Accuracy: {(train_correct/len(train_loader)):.4f}% Train Loss: {(train_loss/len(train_loader)):.4f}")

        model.eval()

        for data in val_loader:
            images, labels = data

            if torch.cuda.is_available():
                images, labels = images.cuda(), labels.cuda()

            outputs = model(images)
            loss = criterion(outputs, labels)

            _, predictions = torch.max(outputs.data, 1)
            val_correct += sum(predictions == labels)/len(predictions == labels)
            val_loss += loss.item()

        val_losses.append(val_loss/len(val_loader))
        val_accuracy.append(val_correct/len(val_loader))
        print(f"Epoch: {epoch+1} Validation Accuracy: {(val_correct/len(val_loader)):.4f}% Validation Loss: {(val_loss/len(val_loader)):.4f}")
    return train_losses, train_accuracy, val_losses, val_accuracy

EPOCHS = 15
train_losses, train_accuracy, val_losses, val_accuracy = train_model(model, train_loader,
                                                                       val_loader, optimizer, criterion, EPOCHS)

"""## Confuson matrix"""

import torch
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import numpy as np

def plot_confusion_matrix(model, dataloader, class_names):
    model.eval()

    all_preds = []
    all_labels = []

    with torch.no_grad():
        for images, labels in dataloader:
            if torch.cuda.is_available():
                images, labels = images.cuda(), labels.cuda()

            outputs = model(images)
            _, predictions = torch.max(outputs, 1)

            all_preds.extend(predictions.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # Compute confusion matrix
    cm = confusion_matrix(all_labels, all_preds)

    # Plot confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title('Confusion Matrix')
    plt.show()

# Example usage
class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']  # Replace with actual class names
plot_confusion_matrix(model, val_loader, class_names)

"""Plot the training loss (and validation loss/accuracy, if recorded)."""

## YOUR CODE HERE ##
def plot_loss_accuracy(train_losses, train_accuracy, val_losses, val_accuracy):
    plt.figure(figsize = (12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(train_losses)
    plt.plot(val_losses)
    plt.legend(["Train", "Validation"])
    plt.xlabel("Epochs")
    plt.ylabel("Losses")
    plt.title("Train and Validation losses")

    plt.subplot(1, 2, 2)
    plt.plot(train_accuracy)
    plt.plot(val_accuracy)
    plt.legend(["Train", "Validation"])
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.title("Train and Validation accuracy")
plot_loss_accuracy(train_losses, train_accuracy, val_losses, val_accuracy)

"""## Testing your model
Using the previously created `DataLoader` for the test set, compute the percentage of correct predictions using the highest probability prediction.

If your accuracy is over 90%, great work, but see if you can push a bit further!
If your accuracy is under 90%, you'll need to make improvements.
Go back and check your model architecture, loss function, and optimizer to make sure they're appropriate for an image classification task.
"""

test_correct = 0
for data in test_loader:
    images, labels = data

    if torch.cuda.is_available():
        images, labels = images.cuda(), labels.cuda()

    outputs = model(images)

    _, predictions = torch.max(outputs.data, 1)
    test_correct += sum(predictions == labels)/len(predictions == labels)

print("The test accuracy is: {}".format(test_correct/len(test_loader)))

"""## Improving your model

Once your model is done training, try tweaking your hyperparameters and training again below to improve your accuracy on the test set!

#### Increased the number of layers and epochs. Also reduced the learning rate
"""

class model(nn.Module):
    def __init__(self):
        super().__init__()
        self.activation = F.relu
        self.layer1 = nn.Linear(784, 512)
        self.layer2 = nn.Linear(512, 256)
        self.layer3 = nn.Linear(256, 128)
        self.layer4 = nn.Linear(128, 64)
        self.layer5 = nn.Linear(64, 10)

    def forward(self, x):
        x =  torch.flatten(x, 1)
        x = self.activation(self.layer1(x))
        x = self.activation(self.layer2(x))
        x = self.activation(self.layer3(x))
        x = self.activation(self.layer4(x))
        return self.layer5(x)

# Initialize the network, loss function, and optimizer
new_model = model()

optimizer = optim.SGD(new_model.parameters(), lr=0.005, momentum=0.9)

EPOCHS = 20
new_train_losses, new_train_accuracy, new_val_losses, new_val_accuracy = train_model(new_model, train_loader,
                                                                                      val_loader, optimizer, criterion, EPOCHS)

"""### Confusion Matrix of improved model"""

plot_confusion_matrix(new_model, val_loader, class_names)

new_train_accuracy = [_.cpu().numpy() for _ in new_train_accuracy]
new_val_accuracy = [_.cpu().numpy() for _ in new_val_accuracy]

plot_loss_accuracy(new_train_losses, new_train_accuracy, new_val_losses, new_val_accuracy)

test_correct = 0
for data in test_loader:
    images, labels = data

    if torch.cuda.is_available():
        images, labels = images.cuda(), labels.cuda()

    outputs = new_model(images)

    _, predictions = torch.max(outputs.data, 1)
    test_correct += sum(predictions == labels)/len(predictions == labels)

print("The new test accuracy is: {}".format(test_correct/len(test_loader)))

# prompt: create a confusion matrix

import matplotlib.pyplot as plt
import numpy as np

def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in np.ndindex(cm.shape):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

# Example usage (replace with your actual predictions and true labels)
from sklearn.metrics import confusion_matrix

y_true = []  # Your true labels
y_pred = []  # Your predicted labels


# Assuming 'new_model' and 'test_loader' are defined from the previous code
with torch.no_grad():
    for data in test_loader:
        images, labels = data
        if torch.cuda.is_available():
            images, labels = images.cuda(), labels.cuda()
        outputs = new_model(images)
        _, predicted = torch.max(outputs, 1)

        y_true.extend(labels.cpu().numpy()) # Assuming you're using GPU
        y_pred.extend(predicted.cpu().numpy())

# Compute confusion matrix
cnf_matrix = confusion_matrix(y_true, y_pred)
np.set_printoptions(precision=2)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=np.arange(10), title='Confusion matrix, without normalization')


# Plot normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=np.arange(10), normalize=True, title='Normalized confusion matrix')

"""## Saving your model
Using `torch.save`, save your model for future loading.
"""

MODEL_PATH = os.getcwd()
if "Models" not in os.listdir():
    os.makedirs('Models')
MODEL_PATH = os.path.join(os.getcwd(), "Models\\model.pth")
torch.save(model, MODEL_PATH)

